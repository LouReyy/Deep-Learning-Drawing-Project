# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14XH29R75__zxFrk35Hx457B5bMT6fz_O
"""

import tensorflow as tf
print(tf.__version__)


from quickdraw import QuickDrawData, QuickDrawDataGroup
from pathlib import Path

image_size = (28, 28)

def generate_class_images(name, max_drawings, recognized):
    directory = Path("dataset/" + name)

    if not directory.exists():
        directory.mkdir(parents=True)

    images = QuickDrawDataGroup(name, max_drawings=1200, recognized=recognized)
    for img in images.drawings:
        filename = directory.as_posix() + "/" + str(img.key_id) + ".png"
        img.get_image(stroke_width=3).resize(image_size).save(filename)

for label in QuickDrawData().drawing_names:
    generate_class_images(label, max_drawings=1200, recognized=True)

from tensorflow.keras.preprocessing import image_dataset_from_directory

dataset_dir = 'dataset'

batch_size = 32

import os

# Obtenez les noms de sous-dossiers (classes)
class_names = sorted(os.listdir(dataset_dir))  # Obtenez les noms des sous-dossiers
num_classes = len(class_names)  # Nombre total de classes

# Charger les ensembles de données avec les bons labels
train_ds = image_dataset_from_directory(
    dataset_dir,
    validation_split=0.2,
    subset="training",
    seed=123,
    color_mode="grayscale",
    image_size=image_size,
    batch_size=batch_size,
    label_mode='categorical',  # Utilisez 'categorical' pour obtenir les bons labels
    class_names=class_names  # Fournissez les noms des sous-dossiers comme classes
)

val_ds = image_dataset_from_directory(
    dataset_dir,
    validation_split=0.2,
    subset="validation",
    seed=123,
    color_mode="grayscale",
    image_size=image_size,
    batch_size=batch_size,
    label_mode='categorical',  # Utilisez 'categorical' pour obtenir les bons labels
    class_names=class_names  # Fournissez les noms des sous-dossiers comme classes
)

# Vérifiez le résultat
for images, labels in train_ds.take(1):  # Prenez un batch pour l'exemple
    print("Forme des images dans train_ds :", images.shape)
    print("Forme des étiquettes (labels) dans train_ds :", labels.shape)
    print("Noms des classes dans train_ds :", train_ds.class_names)

for images, labels in val_ds.take(1):  # Prenez un batch pour l'exemple
    print("Forme des images dans val_ds :", images.shape)
    print("Forme des étiquettes (labels) dans val_ds :", labels.shape)
    print("Noms des classes dans val_ds :", val_ds.class_names)


import matplotlib.pyplot as plt

plt.figure(figsize=(8, 8))
for images, labels in train_ds.take(1):
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        data = images[i].numpy().astype("uint8")
        plt.imshow(data, cmap='gray', vmin=0, vmax=255)
        plt.title(train_ds.class_names[labels.numpy()[i].argmax()])
        plt.axis("off")
plt.show()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Rescaling, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Dense, Dropout

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, Rescaling

n_classes = 345
input_shape = (28, 28, 1)

model = Sequential([
    Rescaling(1. / 255, input_shape=input_shape),
    BatchNormalization(),

    Conv2D(6, kernel_size=(3, 3), padding="same", activation="relu"),
    Conv2D(8, kernel_size=(3, 3), padding="same", activation="relu"),
    Conv2D(10, kernel_size=(3, 3), padding="same", activation="relu"),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),

    Flatten(),

    Dense(700, activation="relu"),
    BatchNormalization(),
    Dropout(0.2),

    Dense(500, activation="relu"),
    BatchNormalization(),
    Dropout(0.2),

    Dense(400, activation="relu"),
    Dropout(0.2),

    Dense(n_classes, activation="softmax")
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Afficher le résumé du modèle
model.summary()

import os
import datetime
from tensorflow.keras.callbacks import TensorBoard
from keras.utils import to_categorical

import datetime
import os
from keras.callbacks import TensorBoard

epochs = 14

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = TensorBoard(logdir)  # Retirez histogram_freq=1

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Entraînement du modèle
model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=epochs,
    verbose=1,
    callbacks=[tensorboard_callback]
)

model.save('./models/model_' + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))

# Convert the model
converter = tf.lite.TFLiteConverter.from_saved_model("models\model_20231212-154053")

tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
    f.write(tflite_model)


# Nombre de classes dans l'ensemble de données de validation
num_classes_val = len(val_ds.class_names)
print("Nombre de classes dans l'ensemble de validation :", num_classes_val)
